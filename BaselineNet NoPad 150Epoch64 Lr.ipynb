{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PKL BaselineNet NoPad 150Epoch64 Lr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhASYws3YSLE"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout,LeakyReLU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeeHbLwU9v11"
      },
      "source": [
        "data=[]\n",
        "labels=[]\n",
        "Parasitized=os.listdir(\"/content/drive/My Drive/Colab Notebooks/Dataset/cell_images/Parasitized/\")\n",
        "for a in Parasitized:\n",
        "    try:\n",
        "        image=cv2.imread(\"/content/drive/My Drive/Colab Notebooks/Dataset/cell_images/Parasitized/\"+a)\n",
        "        image_from_array = Image.fromarray(image, 'RGB')\n",
        "        size_image = image_from_array.resize((64, 64))\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append(0)\n",
        "    except AttributeError:\n",
        "        print(\"\")\n",
        "\n",
        "Uninfected=os.listdir(\"/content/drive/My Drive/Colab Notebooks/Dataset/cell_images/Uninfected/\")\n",
        "for b in Uninfected:\n",
        "    try:\n",
        "        image=cv2.imread(\"/content/drive/My Drive/Colab Notebooks/Dataset/cell_images/Uninfected/\"+b)\n",
        "        image_from_array = Image.fromarray(image, 'RGB')\n",
        "        size_image = image_from_array.resize((64, 64))\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append(1)\n",
        "    except AttributeError:\n",
        "        print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIsrtu0vHQzI"
      },
      "source": [
        "Cells=np.array(data)\n",
        "labels=np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAycSC1bHVHd"
      },
      "source": [
        "np.save(\"/content/drive/My Drive/Colab Notebooks/Cells64\",Cells)\n",
        "np.save(\"/content/drive/My Drive/Colab Notebooks/labels64\",labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaM6cU1dYYzO"
      },
      "source": [
        "Cells=np.load(\"/content/drive/My Drive/Colab Notebooks/Cells64.npy\")\n",
        "labels=np.load(\"/content/drive/My Drive/Colab Notebooks/labels64.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9V_zVC0YaCA"
      },
      "source": [
        "s=np.arange(Cells.shape[0])\n",
        "np.random.shuffle(s)\n",
        "Cells=Cells[s]\n",
        "labels=labels[s]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b5rRJNQYbL0"
      },
      "source": [
        "num_classes=len(np.unique(labels))\n",
        "len_data=len(Cells)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhbL5d73Yc6r"
      },
      "source": [
        "(x_train,x_test)=Cells[(int)(0.1*len_data):],Cells[:(int)(0.1*len_data)]\n",
        "x_train = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255\n",
        "train_len=len(x_train)\n",
        "test_len=len(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP5--WW2YdGX"
      },
      "source": [
        "(y_train,y_test)=labels[(int)(0.1*len_data):],labels[:(int)(0.1*len_data)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecDyWuEKYee1"
      },
      "source": [
        "y_train=keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test=keras.utils.to_categorical(y_test,num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piT6UWCWYfpA"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False,  \n",
        "        rotation_range=10,\n",
        "        zoom_range = 0.1,  \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=False,  \n",
        "        vertical_flip=False)  \n",
        " \n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8zBzA-zYiDO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "outputId": "e3160ff9-5e41-40ec-abb3-85f4d444244b"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=(64,64,3)))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3)))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=128,kernel_size=(3,3)))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=256,kernel_size=(3,3)))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(500))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(500))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)   (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)   (None, 29, 29, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 500)               512500    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)   (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)   (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)   (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 2)                 1002      \n",
            "=================================================================\n",
            "Total params: 1,402,918\n",
            "Trainable params: 1,402,918\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfQBOxW_YjU0"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEtUCQCBYk6F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7337327f-2fb5-4b51-a321-62e61e6512e5"
      },
      "source": [
        "history = model.fit(x = x_train, y = y_train,\n",
        "                    epochs = 150, validation_data = (x_test,y_test),\n",
        "                    verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.2171 - accuracy: 0.9166 - val_loss: 0.1367 - val_accuracy: 0.9590\n",
            "Epoch 2/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1465 - accuracy: 0.9546 - val_loss: 0.1352 - val_accuracy: 0.9568\n",
            "Epoch 3/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1372 - accuracy: 0.9556 - val_loss: 0.1227 - val_accuracy: 0.9630\n",
            "Epoch 4/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1316 - accuracy: 0.9581 - val_loss: 0.1225 - val_accuracy: 0.9554\n",
            "Epoch 5/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1248 - accuracy: 0.9591 - val_loss: 0.1047 - val_accuracy: 0.9648\n",
            "Epoch 6/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1151 - accuracy: 0.9623 - val_loss: 0.1158 - val_accuracy: 0.9612\n",
            "Epoch 7/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.5672 - accuracy: 0.9440 - val_loss: 1.3293 - val_accuracy: 0.8552\n",
            "Epoch 8/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1723 - accuracy: 0.9513 - val_loss: 0.1154 - val_accuracy: 0.9637\n",
            "Epoch 9/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0981 - accuracy: 0.9661 - val_loss: 0.1108 - val_accuracy: 0.9612\n",
            "Epoch 10/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0850 - accuracy: 0.9705 - val_loss: 0.1256 - val_accuracy: 0.9546\n",
            "Epoch 11/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0762 - accuracy: 0.9741 - val_loss: 0.1230 - val_accuracy: 0.9612\n",
            "Epoch 12/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0709 - accuracy: 0.9755 - val_loss: 0.1277 - val_accuracy: 0.9554\n",
            "Epoch 13/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0659 - accuracy: 0.9776 - val_loss: 0.1330 - val_accuracy: 0.9601\n",
            "Epoch 14/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0657 - accuracy: 0.9793 - val_loss: 0.1212 - val_accuracy: 0.9604\n",
            "Epoch 15/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0611 - accuracy: 0.9793 - val_loss: 0.1384 - val_accuracy: 0.9554\n",
            "Epoch 16/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0610 - accuracy: 0.9790 - val_loss: 0.1951 - val_accuracy: 0.9521\n",
            "Epoch 17/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0580 - accuracy: 0.9810 - val_loss: 0.1783 - val_accuracy: 0.9561\n",
            "Epoch 18/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0606 - accuracy: 0.9804 - val_loss: 0.2514 - val_accuracy: 0.9376\n",
            "Epoch 19/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0698 - accuracy: 0.9795 - val_loss: 0.2247 - val_accuracy: 0.9572\n",
            "Epoch 20/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.2578 - accuracy: 0.9780 - val_loss: 87.0662 - val_accuracy: 0.4951\n",
            "Epoch 21/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.6202 - accuracy: 0.9546 - val_loss: 0.1853 - val_accuracy: 0.9590\n",
            "Epoch 22/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0420 - accuracy: 0.9859 - val_loss: 0.2324 - val_accuracy: 0.9583\n",
            "Epoch 23/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.2637 - val_accuracy: 0.9568\n",
            "Epoch 24/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.2770 - val_accuracy: 0.9568\n",
            "Epoch 25/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.3059 - val_accuracy: 0.9550\n",
            "Epoch 26/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.2664 - val_accuracy: 0.9583\n",
            "Epoch 27/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.2969 - val_accuracy: 0.9532\n",
            "Epoch 28/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 0.3933 - val_accuracy: 0.9521\n",
            "Epoch 29/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0474 - accuracy: 0.9870 - val_loss: 0.2613 - val_accuracy: 0.9492\n",
            "Epoch 30/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.3440 - val_accuracy: 0.9463\n",
            "Epoch 31/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0368 - accuracy: 0.9883 - val_loss: 0.2950 - val_accuracy: 0.9506\n",
            "Epoch 32/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0528 - accuracy: 0.9864 - val_loss: 0.9863 - val_accuracy: 0.7481\n",
            "Epoch 33/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.2379 - accuracy: 0.9709 - val_loss: 0.3414 - val_accuracy: 0.9546\n",
            "Epoch 34/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.5298 - val_accuracy: 0.9615\n",
            "Epoch 35/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.5909 - val_accuracy: 0.9532\n",
            "Epoch 36/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0262 - accuracy: 0.9929 - val_loss: 0.4862 - val_accuracy: 0.9535\n",
            "Epoch 37/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0266 - accuracy: 0.9917 - val_loss: 0.3702 - val_accuracy: 0.9430\n",
            "Epoch 38/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0316 - accuracy: 0.9917 - val_loss: 0.1745 - val_accuracy: 0.9517\n",
            "Epoch 39/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1713 - accuracy: 0.9757 - val_loss: 0.3733 - val_accuracy: 0.9579\n",
            "Epoch 40/150\n",
            "776/776 [==============================] - 14s 19ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.5469 - val_accuracy: 0.9561\n",
            "Epoch 41/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.4929 - val_accuracy: 0.9532\n",
            "Epoch 42/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.4405 - val_accuracy: 0.9539\n",
            "Epoch 43/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.5928 - accuracy: 0.9734 - val_loss: 0.5798 - val_accuracy: 0.9383\n",
            "Epoch 44/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0358 - accuracy: 0.9898 - val_loss: 0.5448 - val_accuracy: 0.9546\n",
            "Epoch 45/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.5679 - val_accuracy: 0.9550\n",
            "Epoch 46/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.8146 - val_accuracy: 0.9550\n",
            "Epoch 47/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.7239 - val_accuracy: 0.9514\n",
            "Epoch 48/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.8805 - val_accuracy: 0.9579\n",
            "Epoch 49/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.6619 - val_accuracy: 0.9561\n",
            "Epoch 50/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 8.8712 - accuracy: 0.9534 - val_loss: 1.0224 - val_accuracy: 0.9586\n",
            "Epoch 51/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1553 - accuracy: 0.9806 - val_loss: 1.0894 - val_accuracy: 0.9459\n",
            "Epoch 52/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0715 - accuracy: 0.9883 - val_loss: 1.1316 - val_accuracy: 0.9575\n",
            "Epoch 53/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0489 - accuracy: 0.9917 - val_loss: 1.5628 - val_accuracy: 0.9517\n",
            "Epoch 54/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0427 - accuracy: 0.9930 - val_loss: 1.5536 - val_accuracy: 0.9514\n",
            "Epoch 55/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0550 - accuracy: 0.9938 - val_loss: 1.2072 - val_accuracy: 0.9503\n",
            "Epoch 56/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0435 - accuracy: 0.9935 - val_loss: 1.4247 - val_accuracy: 0.9528\n",
            "Epoch 57/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0241 - accuracy: 0.9962 - val_loss: 1.5558 - val_accuracy: 0.9528\n",
            "Epoch 58/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0790 - accuracy: 0.9927 - val_loss: 1.4842 - val_accuracy: 0.9514\n",
            "Epoch 59/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0198 - accuracy: 0.9956 - val_loss: 0.9521 - val_accuracy: 0.9583\n",
            "Epoch 60/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 1.0445 - val_accuracy: 0.9477\n",
            "Epoch 61/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0454 - accuracy: 0.9917 - val_loss: 0.6042 - val_accuracy: 0.9525\n",
            "Epoch 62/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0438 - accuracy: 0.9922 - val_loss: 2.0537 - val_accuracy: 0.9365\n",
            "Epoch 63/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0861 - accuracy: 0.9885 - val_loss: 0.5317 - val_accuracy: 0.9528\n",
            "Epoch 64/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0770 - accuracy: 0.9878 - val_loss: 0.9894 - val_accuracy: 0.9554\n",
            "Epoch 65/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.7181 - val_accuracy: 0.9543\n",
            "Epoch 66/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1357 - accuracy: 0.9923 - val_loss: 5.6823 - val_accuracy: 0.8254\n",
            "Epoch 67/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.6452 - accuracy: 0.9818 - val_loss: 0.9286 - val_accuracy: 0.9528\n",
            "Epoch 68/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 1.0689 - val_accuracy: 0.9532\n",
            "Epoch 69/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 1.2595 - val_accuracy: 0.9568\n",
            "Epoch 70/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 1.3311 - val_accuracy: 0.9550\n",
            "Epoch 71/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0410 - accuracy: 0.9927 - val_loss: 1.0401 - val_accuracy: 0.9586\n",
            "Epoch 72/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.8508 - val_accuracy: 0.9561\n",
            "Epoch 73/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1357 - accuracy: 0.9838 - val_loss: 0.5350 - val_accuracy: 0.9263\n",
            "Epoch 74/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0224 - accuracy: 0.9946 - val_loss: 0.8114 - val_accuracy: 0.9554\n",
            "Epoch 75/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.9514 - val_accuracy: 0.9572\n",
            "Epoch 76/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 4.5120 - accuracy: 0.9592 - val_loss: 1.1300 - val_accuracy: 0.9546\n",
            "Epoch 77/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0834 - accuracy: 0.9863 - val_loss: 1.0216 - val_accuracy: 0.9521\n",
            "Epoch 78/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0369 - accuracy: 0.9919 - val_loss: 1.2154 - val_accuracy: 0.9481\n",
            "Epoch 79/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0245 - accuracy: 0.9950 - val_loss: 1.6166 - val_accuracy: 0.9517\n",
            "Epoch 80/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 1.3507 - val_accuracy: 0.9503\n",
            "Epoch 81/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0150 - accuracy: 0.9967 - val_loss: 1.4632 - val_accuracy: 0.9510\n",
            "Epoch 82/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0338 - accuracy: 0.9950 - val_loss: 1.8133 - val_accuracy: 0.9554\n",
            "Epoch 83/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 1.5453 - val_accuracy: 0.9510\n",
            "Epoch 84/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.6209 - accuracy: 0.9898 - val_loss: 6.1242 - val_accuracy: 0.9477\n",
            "Epoch 85/150\n",
            "776/776 [==============================] - 14s 19ms/step - loss: 0.3912 - accuracy: 0.9856 - val_loss: 2.0718 - val_accuracy: 0.9495\n",
            "Epoch 86/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 2.2423 - val_accuracy: 0.9535\n",
            "Epoch 87/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0139 - accuracy: 0.9977 - val_loss: 1.9290 - val_accuracy: 0.9521\n",
            "Epoch 88/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0371 - accuracy: 0.9957 - val_loss: 1.7973 - val_accuracy: 0.9506\n",
            "Epoch 89/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.2462 - accuracy: 0.9877 - val_loss: 2.2862 - val_accuracy: 0.9499\n",
            "Epoch 90/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0201 - accuracy: 0.9967 - val_loss: 1.1537 - val_accuracy: 0.9383\n",
            "Epoch 91/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1937 - accuracy: 0.9891 - val_loss: 3.7561 - val_accuracy: 0.9495\n",
            "Epoch 92/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.2478 - accuracy: 0.9854 - val_loss: 1.3937 - val_accuracy: 0.9456\n",
            "Epoch 93/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0227 - accuracy: 0.9957 - val_loss: 1.3487 - val_accuracy: 0.9481\n",
            "Epoch 94/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 1.2347 - val_accuracy: 0.9510\n",
            "Epoch 95/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 1.1120 - val_accuracy: 0.9452\n",
            "Epoch 96/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1229 - accuracy: 0.9920 - val_loss: 6.9583 - val_accuracy: 0.9419\n",
            "Epoch 97/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.5671 - accuracy: 0.9808 - val_loss: 2.1780 - val_accuracy: 0.9485\n",
            "Epoch 98/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0246 - accuracy: 0.9966 - val_loss: 2.3098 - val_accuracy: 0.9488\n",
            "Epoch 99/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 2.0369 - val_accuracy: 0.9510\n",
            "Epoch 100/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 1.8424 - val_accuracy: 0.9459\n",
            "Epoch 101/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.7598 - accuracy: 0.9850 - val_loss: 4.7316 - val_accuracy: 0.9445\n",
            "Epoch 102/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0921 - accuracy: 0.9933 - val_loss: 4.8937 - val_accuracy: 0.9517\n",
            "Epoch 103/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0207 - accuracy: 0.9979 - val_loss: 3.7653 - val_accuracy: 0.9525\n",
            "Epoch 104/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0234 - accuracy: 0.9978 - val_loss: 2.3564 - val_accuracy: 0.9546\n",
            "Epoch 105/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1795 - accuracy: 0.9911 - val_loss: 2.4160 - val_accuracy: 0.9546\n",
            "Epoch 106/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0131 - accuracy: 0.9983 - val_loss: 4.3785 - val_accuracy: 0.9394\n",
            "Epoch 107/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.5924 - accuracy: 0.9840 - val_loss: 2.7913 - val_accuracy: 0.9488\n",
            "Epoch 108/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0189 - accuracy: 0.9981 - val_loss: 2.8474 - val_accuracy: 0.9474\n",
            "Epoch 109/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0252 - accuracy: 0.9972 - val_loss: 3.8461 - val_accuracy: 0.9579\n",
            "Epoch 110/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 2.7350 - accuracy: 0.9761 - val_loss: 6.3472 - val_accuracy: 0.9474\n",
            "Epoch 111/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0963 - accuracy: 0.9933 - val_loss: 4.6562 - val_accuracy: 0.9510\n",
            "Epoch 112/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0436 - accuracy: 0.9964 - val_loss: 5.2869 - val_accuracy: 0.9463\n",
            "Epoch 113/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0227 - accuracy: 0.9979 - val_loss: 6.4662 - val_accuracy: 0.9503\n",
            "Epoch 114/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0674 - accuracy: 0.9958 - val_loss: 4.7998 - val_accuracy: 0.9539\n",
            "Epoch 115/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0307 - accuracy: 0.9980 - val_loss: 4.3063 - val_accuracy: 0.9521\n",
            "Epoch 116/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.4287 - accuracy: 0.9904 - val_loss: 3.4560 - val_accuracy: 0.9459\n",
            "Epoch 117/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1353 - accuracy: 0.9940 - val_loss: 2.4778 - val_accuracy: 0.9543\n",
            "Epoch 118/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0193 - accuracy: 0.9984 - val_loss: 3.4932 - val_accuracy: 0.9539\n",
            "Epoch 119/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0200 - accuracy: 0.9975 - val_loss: 4.5219 - val_accuracy: 0.9525\n",
            "Epoch 120/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.8020 - accuracy: 0.9851 - val_loss: 3.5917 - val_accuracy: 0.9510\n",
            "Epoch 121/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0283 - accuracy: 0.9975 - val_loss: 3.8516 - val_accuracy: 0.9514\n",
            "Epoch 122/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0247 - accuracy: 0.9981 - val_loss: 4.5331 - val_accuracy: 0.9503\n",
            "Epoch 123/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0705 - accuracy: 0.9957 - val_loss: 5.8405 - val_accuracy: 0.9539\n",
            "Epoch 124/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.8472 - accuracy: 0.9841 - val_loss: 6.9352 - val_accuracy: 0.9510\n",
            "Epoch 125/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1135 - accuracy: 0.9943 - val_loss: 8.4016 - val_accuracy: 0.9528\n",
            "Epoch 126/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1032 - accuracy: 0.9948 - val_loss: 5.2550 - val_accuracy: 0.9532\n",
            "Epoch 127/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0509 - accuracy: 0.9965 - val_loss: 9.7298 - val_accuracy: 0.9539\n",
            "Epoch 128/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1854 - accuracy: 0.9913 - val_loss: 5.2673 - val_accuracy: 0.9470\n",
            "Epoch 129/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0374 - accuracy: 0.9969 - val_loss: 4.0609 - val_accuracy: 0.9445\n",
            "Epoch 130/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0528 - accuracy: 0.9958 - val_loss: 5.9205 - val_accuracy: 0.9456\n",
            "Epoch 131/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 2.6492 - accuracy: 0.9851 - val_loss: 7.7537 - val_accuracy: 0.9543\n",
            "Epoch 132/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0559 - accuracy: 0.9974 - val_loss: 9.9857 - val_accuracy: 0.9525\n",
            "Epoch 133/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0448 - accuracy: 0.9977 - val_loss: 8.1213 - val_accuracy: 0.9517\n",
            "Epoch 134/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1265 - accuracy: 0.9967 - val_loss: 7.7294 - val_accuracy: 0.9463\n",
            "Epoch 135/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1847 - accuracy: 0.9951 - val_loss: 5.5059 - val_accuracy: 0.9517\n",
            "Epoch 136/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0599 - accuracy: 0.9973 - val_loss: 7.4155 - val_accuracy: 0.9445\n",
            "Epoch 137/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0493 - accuracy: 0.9969 - val_loss: 9.0031 - val_accuracy: 0.9517\n",
            "Epoch 138/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.7819 - accuracy: 0.9891 - val_loss: 15.3974 - val_accuracy: 0.9503\n",
            "Epoch 139/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.3392 - accuracy: 0.9923 - val_loss: 12.3083 - val_accuracy: 0.9463\n",
            "Epoch 140/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.1052 - accuracy: 0.9960 - val_loss: 9.5613 - val_accuracy: 0.9546\n",
            "Epoch 141/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0819 - accuracy: 0.9961 - val_loss: 6.8110 - val_accuracy: 0.9525\n",
            "Epoch 142/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0605 - accuracy: 0.9973 - val_loss: 10.3303 - val_accuracy: 0.9532\n",
            "Epoch 143/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.8606 - accuracy: 0.9863 - val_loss: 7.6289 - val_accuracy: 0.9463\n",
            "Epoch 144/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0373 - accuracy: 0.9974 - val_loss: 10.0038 - val_accuracy: 0.9535\n",
            "Epoch 145/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0870 - accuracy: 0.9966 - val_loss: 9.5048 - val_accuracy: 0.9485\n",
            "Epoch 146/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.9350 - accuracy: 0.9865 - val_loss: 6.8682 - val_accuracy: 0.9506\n",
            "Epoch 147/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0377 - accuracy: 0.9977 - val_loss: 8.2343 - val_accuracy: 0.9528\n",
            "Epoch 148/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.0271 - accuracy: 0.9981 - val_loss: 8.5378 - val_accuracy: 0.9499\n",
            "Epoch 149/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.3040 - accuracy: 0.9913 - val_loss: 14.8563 - val_accuracy: 0.9470\n",
            "Epoch 150/150\n",
            "776/776 [==============================] - 14s 18ms/step - loss: 0.8033 - accuracy: 0.9904 - val_loss: 11.7505 - val_accuracy: 0.9419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRjZd96tiA_w"
      },
      "source": [
        "model.save(\"/content/drive/My Drive/Colab Notebooks/Baselinenet_nopad_150epoch64_lr/BaselineNetNoPad150Epoch64Lr.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_rgcIljZtxY"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "pred = model.predict(x_test)\n",
        "pred = np.argmax(pred,axis = 1) \n",
        "y_true = np.argmax(y_test,axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIJGnOAuZu8Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "7b7b55ec-82de-48d4-ddd5-96013d8c8218"
      },
      "source": [
        "CM = confusion_matrix(y_true, pred)\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}