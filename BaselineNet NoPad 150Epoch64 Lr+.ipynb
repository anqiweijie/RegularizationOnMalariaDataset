{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PKL BaselineNet NoPad 150Epoch64 Lr+.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhASYws3YSLE"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout,LeakyReLU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeeHbLwU9v11"
      },
      "source": [
        "data=[]\n",
        "labels=[]\n",
        "Parasitized=os.listdir(\"/content/drive/My Drive/Colab Notebooks/Dataset/cell_images/Parasitized/\")\n",
        "for a in Parasitized:\n",
        "    try:\n",
        "        image=cv2.imread(\"/content/drive/My Drive/Colab Notebooks/Dataset/cell_images/Parasitized/\"+a)\n",
        "        image_from_array = Image.fromarray(image, 'RGB')\n",
        "        size_image = image_from_array.resize((64, 64))\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append(0)\n",
        "    except AttributeError:\n",
        "        print(\"\")\n",
        "\n",
        "Uninfected=os.listdir(\"/content/drive/My Drive/Colab Notebooks/Dataset/cell_images/Uninfected/\")\n",
        "for b in Uninfected:\n",
        "    try:\n",
        "        image=cv2.imread(\"/content/drive/My Drive/Colab Notebooks/Dataset/cell_images/Uninfected/\"+b)\n",
        "        image_from_array = Image.fromarray(image, 'RGB')\n",
        "        size_image = image_from_array.resize((64, 64))\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append(1)\n",
        "    except AttributeError:\n",
        "        print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIsrtu0vHQzI"
      },
      "source": [
        "Cells=np.array(data)\n",
        "labels=np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAycSC1bHVHd"
      },
      "source": [
        "np.save(\"/content/drive/My Drive/Colab Notebooks/Cells64\",Cells)\n",
        "np.save(\"/content/drive/My Drive/Colab Notebooks/labels64\",labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaM6cU1dYYzO"
      },
      "source": [
        "Cells=np.load(\"/content/drive/My Drive/Colab Notebooks/Cells64.npy\")\n",
        "labels=np.load(\"/content/drive/My Drive/Colab Notebooks/labels64.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9V_zVC0YaCA"
      },
      "source": [
        "s=np.arange(Cells.shape[0])\n",
        "np.random.shuffle(s)\n",
        "Cells=Cells[s]\n",
        "labels=labels[s]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b5rRJNQYbL0"
      },
      "source": [
        "num_classes=len(np.unique(labels))\n",
        "len_data=len(Cells)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhbL5d73Yc6r"
      },
      "source": [
        "(x_train,x_test)=Cells[(int)(0.1*len_data):],Cells[:(int)(0.1*len_data)]\n",
        "x_train = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255\n",
        "train_len=len(x_train)\n",
        "test_len=len(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP5--WW2YdGX"
      },
      "source": [
        "(y_train,y_test)=labels[(int)(0.1*len_data):],labels[:(int)(0.1*len_data)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecDyWuEKYee1"
      },
      "source": [
        "y_train=keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test=keras.utils.to_categorical(y_test,num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piT6UWCWYfpA"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=True,\n",
        "        samplewise_center=True,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False,\n",
        "        rotation_range=10,\n",
        "        zoom_range = 0.1,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True)\n",
        " \n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8zBzA-zYiDO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "outputId": "b64feb6f-baa5-43e1-f7de-d847e904a8e0"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=(64,64,3)))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3)))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=128,kernel_size=(3,3)))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=256,kernel_size=(3,3)))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(500))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(500))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_40 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_70 (LeakyReLU)   (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_71 (LeakyReLU)   (None, 29, 29, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_72 (LeakyReLU)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_73 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 500)               512500    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_74 (LeakyReLU)   (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_75 (LeakyReLU)   (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_76 (LeakyReLU)   (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 2)                 1002      \n",
            "=================================================================\n",
            "Total params: 1,402,918\n",
            "Trainable params: 1,402,918\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfQBOxW_YjU0"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEtUCQCBYk6F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ddd306f6-dcac-4bd9-c072-9d8cadc18f90"
      },
      "source": [
        "history = model.fit(x = x_train, y = y_train,\n",
        "                    epochs = 150, validation_data = (x_test,y_test),\n",
        "                    verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "776/776 [==============================] - 7s 9ms/step - loss: 0.2352 - accuracy: 0.9051 - val_loss: 0.1804 - val_accuracy: 0.9525\n",
            "Epoch 2/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1455 - accuracy: 0.9558 - val_loss: 0.1865 - val_accuracy: 0.9423\n",
            "Epoch 3/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1383 - accuracy: 0.9561 - val_loss: 0.1312 - val_accuracy: 0.9564\n",
            "Epoch 4/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1294 - accuracy: 0.9583 - val_loss: 0.1500 - val_accuracy: 0.9554\n",
            "Epoch 5/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1229 - accuracy: 0.9609 - val_loss: 0.1531 - val_accuracy: 0.9412\n",
            "Epoch 6/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1235 - accuracy: 0.9603 - val_loss: 0.1317 - val_accuracy: 0.9499\n",
            "Epoch 7/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1132 - accuracy: 0.9637 - val_loss: 0.1243 - val_accuracy: 0.9532\n",
            "Epoch 8/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1016 - accuracy: 0.9664 - val_loss: 0.1661 - val_accuracy: 0.9532\n",
            "Epoch 9/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0939 - accuracy: 0.9692 - val_loss: 0.1473 - val_accuracy: 0.9481\n",
            "Epoch 10/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0865 - accuracy: 0.9715 - val_loss: 0.2637 - val_accuracy: 0.9038\n",
            "Epoch 11/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0791 - accuracy: 0.9739 - val_loss: 0.1861 - val_accuracy: 0.9343\n",
            "Epoch 12/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0660 - accuracy: 0.9780 - val_loss: 0.2215 - val_accuracy: 0.9535\n",
            "Epoch 13/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1453 - accuracy: 0.9677 - val_loss: 0.2361 - val_accuracy: 0.9383\n",
            "Epoch 14/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0517 - accuracy: 0.9831 - val_loss: 0.2164 - val_accuracy: 0.9481\n",
            "Epoch 15/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.2024 - val_accuracy: 0.9517\n",
            "Epoch 16/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0289 - accuracy: 0.9900 - val_loss: 0.2862 - val_accuracy: 0.9495\n",
            "Epoch 17/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 0.2689 - val_accuracy: 0.9441\n",
            "Epoch 18/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0397 - accuracy: 0.9858 - val_loss: 0.3963 - val_accuracy: 0.9488\n",
            "Epoch 19/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0653 - accuracy: 0.9830 - val_loss: 0.3367 - val_accuracy: 0.9448\n",
            "Epoch 20/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.2231 - val_accuracy: 0.9470\n",
            "Epoch 21/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0371 - accuracy: 0.9884 - val_loss: 0.2022 - val_accuracy: 0.9470\n",
            "Epoch 22/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0370 - accuracy: 0.9890 - val_loss: 0.2740 - val_accuracy: 0.9525\n",
            "Epoch 23/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0485 - accuracy: 0.9858 - val_loss: 0.3273 - val_accuracy: 0.9510\n",
            "Epoch 24/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0310 - accuracy: 0.9902 - val_loss: 0.5468 - val_accuracy: 0.9506\n",
            "Epoch 25/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0619 - accuracy: 0.9829 - val_loss: 0.3355 - val_accuracy: 0.9503\n",
            "Epoch 26/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.5671 - val_accuracy: 0.9506\n",
            "Epoch 27/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0739 - accuracy: 0.9835 - val_loss: 0.3274 - val_accuracy: 0.9514\n",
            "Epoch 28/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0204 - accuracy: 0.9943 - val_loss: 0.4786 - val_accuracy: 0.9492\n",
            "Epoch 29/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.9753 - accuracy: 0.9637 - val_loss: 0.3685 - val_accuracy: 0.9445\n",
            "Epoch 30/150\n",
            "776/776 [==============================] - 7s 9ms/step - loss: 0.0341 - accuracy: 0.9895 - val_loss: 0.4677 - val_accuracy: 0.9481\n",
            "Epoch 31/150\n",
            "776/776 [==============================] - 7s 9ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.6446 - val_accuracy: 0.9477\n",
            "Epoch 32/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.6274 - val_accuracy: 0.9445\n",
            "Epoch 33/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.6761 - val_accuracy: 0.9499\n",
            "Epoch 34/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0287 - accuracy: 0.9942 - val_loss: 0.7195 - val_accuracy: 0.9426\n",
            "Epoch 35/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.4523 - val_accuracy: 0.9492\n",
            "Epoch 36/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.8999 - val_accuracy: 0.9499\n",
            "Epoch 37/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0303 - accuracy: 0.9923 - val_loss: 0.6472 - val_accuracy: 0.9452\n",
            "Epoch 38/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 1.4213 - accuracy: 0.9606 - val_loss: 0.2218 - val_accuracy: 0.9535\n",
            "Epoch 39/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0810 - accuracy: 0.9748 - val_loss: 0.3211 - val_accuracy: 0.9437\n",
            "Epoch 40/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0404 - accuracy: 0.9866 - val_loss: 0.3631 - val_accuracy: 0.9495\n",
            "Epoch 41/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.4782 - val_accuracy: 0.9503\n",
            "Epoch 42/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.6038 - val_accuracy: 0.9510\n",
            "Epoch 43/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.6105 - val_accuracy: 0.9466\n",
            "Epoch 44/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0211 - accuracy: 0.9947 - val_loss: 0.6947 - val_accuracy: 0.9401\n",
            "Epoch 45/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0248 - accuracy: 0.9938 - val_loss: 0.5644 - val_accuracy: 0.9485\n",
            "Epoch 46/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 1.0740 - val_accuracy: 0.9463\n",
            "Epoch 47/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.2895 - accuracy: 0.9794 - val_loss: 0.7008 - val_accuracy: 0.9474\n",
            "Epoch 48/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0175 - accuracy: 0.9958 - val_loss: 0.8873 - val_accuracy: 0.9503\n",
            "Epoch 49/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1096 - accuracy: 0.9907 - val_loss: 1.1334 - val_accuracy: 0.9470\n",
            "Epoch 50/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0375 - accuracy: 0.9929 - val_loss: 0.8387 - val_accuracy: 0.9510\n",
            "Epoch 51/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 1.1008 - val_accuracy: 0.9528\n",
            "Epoch 52/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0217 - accuracy: 0.9952 - val_loss: 0.8856 - val_accuracy: 0.9459\n",
            "Epoch 53/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.3207 - accuracy: 0.9882 - val_loss: 6.1435 - val_accuracy: 0.8704\n",
            "Epoch 54/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.4406 - accuracy: 0.9829 - val_loss: 0.8142 - val_accuracy: 0.9426\n",
            "Epoch 55/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 1.0333 - val_accuracy: 0.9434\n",
            "Epoch 56/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 1.3284 - val_accuracy: 0.9456\n",
            "Epoch 57/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 1.1714 - val_accuracy: 0.9503\n",
            "Epoch 58/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 1.0534 - val_accuracy: 0.9419\n",
            "Epoch 59/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.8953 - accuracy: 0.9803 - val_loss: 0.8457 - val_accuracy: 0.9510\n",
            "Epoch 60/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0273 - accuracy: 0.9930 - val_loss: 0.7544 - val_accuracy: 0.9474\n",
            "Epoch 61/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 1.1828 - val_accuracy: 0.9452\n",
            "Epoch 62/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 1.1473 - val_accuracy: 0.9543\n",
            "Epoch 63/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0241 - accuracy: 0.9954 - val_loss: 1.0827 - val_accuracy: 0.9514\n",
            "Epoch 64/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0630 - accuracy: 0.9917 - val_loss: 1.4053 - val_accuracy: 0.9408\n",
            "Epoch 65/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0206 - accuracy: 0.9958 - val_loss: 1.1709 - val_accuracy: 0.9437\n",
            "Epoch 66/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.5511 - accuracy: 0.9814 - val_loss: 1.3696 - val_accuracy: 0.9488\n",
            "Epoch 67/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0689 - accuracy: 0.9900 - val_loss: 1.7674 - val_accuracy: 0.9434\n",
            "Epoch 68/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 1.9383 - val_accuracy: 0.9528\n",
            "Epoch 69/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 1.4456 - val_accuracy: 0.9488\n",
            "Epoch 70/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0757 - accuracy: 0.9926 - val_loss: 1.1473 - val_accuracy: 0.9412\n",
            "Epoch 71/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0513 - accuracy: 0.9924 - val_loss: 3.6193 - val_accuracy: 0.9448\n",
            "Epoch 72/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.3125 - accuracy: 0.9818 - val_loss: 1.6772 - val_accuracy: 0.9488\n",
            "Epoch 73/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 1.9714 - val_accuracy: 0.9452\n",
            "Epoch 74/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0417 - accuracy: 0.9941 - val_loss: 1.6484 - val_accuracy: 0.9441\n",
            "Epoch 75/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 1.5479 - val_accuracy: 0.9474\n",
            "Epoch 76/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.2106 - accuracy: 0.9869 - val_loss: 0.8702 - val_accuracy: 0.9517\n",
            "Epoch 77/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0193 - accuracy: 0.9959 - val_loss: 1.5569 - val_accuracy: 0.9470\n",
            "Epoch 78/150\n",
            "776/776 [==============================] - 7s 9ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 1.4442 - val_accuracy: 0.9318\n",
            "Epoch 79/150\n",
            "776/776 [==============================] - 7s 9ms/step - loss: 2.9091 - accuracy: 0.9748 - val_loss: 4.3380 - val_accuracy: 0.9477\n",
            "Epoch 80/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0854 - accuracy: 0.9950 - val_loss: 5.2934 - val_accuracy: 0.9445\n",
            "Epoch 81/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0392 - accuracy: 0.9974 - val_loss: 5.9812 - val_accuracy: 0.9510\n",
            "Epoch 82/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0669 - accuracy: 0.9965 - val_loss: 6.4240 - val_accuracy: 0.9517\n",
            "Epoch 83/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0236 - accuracy: 0.9985 - val_loss: 10.2352 - val_accuracy: 0.9445\n",
            "Epoch 84/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.1092 - accuracy: 0.9946 - val_loss: 3.3295 - val_accuracy: 0.9495\n",
            "Epoch 85/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0315 - accuracy: 0.9971 - val_loss: 5.1562 - val_accuracy: 0.9481\n",
            "Epoch 86/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0993 - accuracy: 0.9923 - val_loss: 3.7155 - val_accuracy: 0.9495\n",
            "Epoch 87/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.5313 - accuracy: 0.9872 - val_loss: 3.8331 - val_accuracy: 0.9390\n",
            "Epoch 88/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.1173 - accuracy: 0.9916 - val_loss: 3.5900 - val_accuracy: 0.9492\n",
            "Epoch 89/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1007 - accuracy: 0.9943 - val_loss: 2.2078 - val_accuracy: 0.9474\n",
            "Epoch 90/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0342 - accuracy: 0.9963 - val_loss: 2.2596 - val_accuracy: 0.9488\n",
            "Epoch 91/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 2.8447 - val_accuracy: 0.9481\n",
            "Epoch 92/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.2722 - accuracy: 0.9863 - val_loss: 2.0649 - val_accuracy: 0.9336\n",
            "Epoch 93/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0412 - accuracy: 0.9950 - val_loss: 1.5318 - val_accuracy: 0.9506\n",
            "Epoch 94/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0449 - accuracy: 0.9956 - val_loss: 7.2762 - val_accuracy: 0.9456\n",
            "Epoch 95/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.2009 - accuracy: 0.9880 - val_loss: 2.6254 - val_accuracy: 0.9463\n",
            "Epoch 96/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0311 - accuracy: 0.9963 - val_loss: 3.7363 - val_accuracy: 0.9445\n",
            "Epoch 97/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.2733 - accuracy: 0.9877 - val_loss: 3.7809 - val_accuracy: 0.9517\n",
            "Epoch 98/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0631 - accuracy: 0.9954 - val_loss: 5.0937 - val_accuracy: 0.9485\n",
            "Epoch 99/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.3001 - accuracy: 0.9898 - val_loss: 4.4177 - val_accuracy: 0.9416\n",
            "Epoch 100/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0815 - accuracy: 0.9945 - val_loss: 8.6207 - val_accuracy: 0.9426\n",
            "Epoch 101/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 2.6999 - accuracy: 0.9848 - val_loss: 5.4433 - val_accuracy: 0.9474\n",
            "Epoch 102/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0572 - accuracy: 0.9972 - val_loss: 5.0115 - val_accuracy: 0.9492\n",
            "Epoch 103/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0234 - accuracy: 0.9981 - val_loss: 5.7333 - val_accuracy: 0.9528\n",
            "Epoch 104/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0130 - accuracy: 0.9989 - val_loss: 8.0090 - val_accuracy: 0.9481\n",
            "Epoch 105/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0861 - accuracy: 0.9967 - val_loss: 6.7153 - val_accuracy: 0.9499\n",
            "Epoch 106/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.1034 - accuracy: 0.9957 - val_loss: 10.9265 - val_accuracy: 0.9495\n",
            "Epoch 107/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.3435 - accuracy: 0.9916 - val_loss: 4.1730 - val_accuracy: 0.9405\n",
            "Epoch 108/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0467 - accuracy: 0.9970 - val_loss: 3.5666 - val_accuracy: 0.9401\n",
            "Epoch 109/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0414 - accuracy: 0.9973 - val_loss: 7.9003 - val_accuracy: 0.9397\n",
            "Epoch 110/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.2698 - accuracy: 0.9907 - val_loss: 6.4117 - val_accuracy: 0.9445\n",
            "Epoch 111/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1085 - accuracy: 0.9946 - val_loss: 3.5112 - val_accuracy: 0.9481\n",
            "Epoch 112/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 3.3259 - val_accuracy: 0.9441\n",
            "Epoch 113/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 13.1002 - accuracy: 0.9819 - val_loss: 12.9859 - val_accuracy: 0.9230\n",
            "Epoch 114/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.8773 - accuracy: 0.9733 - val_loss: 3.0821 - val_accuracy: 0.9470\n",
            "Epoch 115/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.2518 - accuracy: 0.9839 - val_loss: 3.7491 - val_accuracy: 0.9434\n",
            "Epoch 116/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1235 - accuracy: 0.9892 - val_loss: 3.7950 - val_accuracy: 0.9401\n",
            "Epoch 117/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0809 - accuracy: 0.9912 - val_loss: 4.5007 - val_accuracy: 0.9405\n",
            "Epoch 118/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0537 - accuracy: 0.9939 - val_loss: 4.1763 - val_accuracy: 0.9481\n",
            "Epoch 119/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.1395 - accuracy: 0.9916 - val_loss: 4.0661 - val_accuracy: 0.9459\n",
            "Epoch 120/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0546 - accuracy: 0.9953 - val_loss: 5.5285 - val_accuracy: 0.9506\n",
            "Epoch 121/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 1.7253 - accuracy: 0.9888 - val_loss: 16.0615 - val_accuracy: 0.9506\n",
            "Epoch 122/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0982 - accuracy: 0.9970 - val_loss: 14.1109 - val_accuracy: 0.9492\n",
            "Epoch 123/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0969 - accuracy: 0.9973 - val_loss: 15.1187 - val_accuracy: 0.9463\n",
            "Epoch 124/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0244 - accuracy: 0.9988 - val_loss: 16.0210 - val_accuracy: 0.9339\n",
            "Epoch 125/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0715 - accuracy: 0.9980 - val_loss: 11.6863 - val_accuracy: 0.9525\n",
            "Epoch 126/150\n",
            "776/776 [==============================] - 7s 9ms/step - loss: 0.0978 - accuracy: 0.9965 - val_loss: 9.7596 - val_accuracy: 0.9339\n",
            "Epoch 127/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 1.2040 - accuracy: 0.9892 - val_loss: 6.6117 - val_accuracy: 0.9525\n",
            "Epoch 128/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0270 - accuracy: 0.9983 - val_loss: 10.3215 - val_accuracy: 0.9514\n",
            "Epoch 129/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0270 - accuracy: 0.9985 - val_loss: 8.8722 - val_accuracy: 0.9506\n",
            "Epoch 130/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0685 - accuracy: 0.9981 - val_loss: 13.4702 - val_accuracy: 0.9401\n",
            "Epoch 131/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 1.7505 - accuracy: 0.9869 - val_loss: 10.4479 - val_accuracy: 0.9488\n",
            "Epoch 132/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0598 - accuracy: 0.9979 - val_loss: 10.1054 - val_accuracy: 0.9463\n",
            "Epoch 133/150\n",
            "776/776 [==============================] - 6s 8ms/step - loss: 0.0122 - accuracy: 0.9991 - val_loss: 10.7906 - val_accuracy: 0.9492\n",
            "Epoch 134/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1155 - accuracy: 0.9965 - val_loss: 8.9047 - val_accuracy: 0.9456\n",
            "Epoch 135/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0829 - accuracy: 0.9965 - val_loss: 6.6443 - val_accuracy: 0.9474\n",
            "Epoch 136/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1132 - accuracy: 0.9954 - val_loss: 7.1909 - val_accuracy: 0.9506\n",
            "Epoch 137/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 1.6051 - accuracy: 0.9875 - val_loss: 12.4055 - val_accuracy: 0.9503\n",
            "Epoch 138/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0703 - accuracy: 0.9973 - val_loss: 12.8545 - val_accuracy: 0.9350\n",
            "Epoch 139/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0733 - accuracy: 0.9975 - val_loss: 9.3077 - val_accuracy: 0.9506\n",
            "Epoch 140/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 1.4183 - accuracy: 0.9892 - val_loss: 13.9787 - val_accuracy: 0.9456\n",
            "Epoch 141/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1697 - accuracy: 0.9968 - val_loss: 12.4588 - val_accuracy: 0.9463\n",
            "Epoch 142/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0956 - accuracy: 0.9974 - val_loss: 9.3750 - val_accuracy: 0.9434\n",
            "Epoch 143/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0789 - accuracy: 0.9974 - val_loss: 10.9683 - val_accuracy: 0.9506\n",
            "Epoch 144/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.8398 - accuracy: 0.9933 - val_loss: 21.0313 - val_accuracy: 0.9430\n",
            "Epoch 145/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1966 - accuracy: 0.9968 - val_loss: 10.1910 - val_accuracy: 0.9474\n",
            "Epoch 146/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0663 - accuracy: 0.9980 - val_loss: 16.0686 - val_accuracy: 0.9463\n",
            "Epoch 147/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 1.8981 - accuracy: 0.9895 - val_loss: 20.5634 - val_accuracy: 0.9514\n",
            "Epoch 148/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.1038 - accuracy: 0.9979 - val_loss: 14.7022 - val_accuracy: 0.9488\n",
            "Epoch 149/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0726 - accuracy: 0.9984 - val_loss: 22.8951 - val_accuracy: 0.9452\n",
            "Epoch 150/150\n",
            "776/776 [==============================] - 7s 8ms/step - loss: 0.0928 - accuracy: 0.9980 - val_loss: 14.1362 - val_accuracy: 0.9456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRjZd96tiA_w"
      },
      "source": [
        "model.save(\"/content/drive/My Drive/Colab Notebooks/Baselinenet_nopad_150epoch64_lr+/BaselineNetNoPad150Epoch64Lr+.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_rgcIljZtxY"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "pred = model.predict(x_test)\n",
        "pred = np.argmax(pred,axis = 1) \n",
        "y_true = np.argmax(y_test,axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIJGnOAuZu8Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "f4c3d785-ee40-4898-e169-c2c33de26f8d"
      },
      "source": [
        "CM = confusion_matrix(y_true, pred)\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}